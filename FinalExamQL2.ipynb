{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definición de clases: Agente y Entorno"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación se definen las clases y métodos necesarios para su uso posterior en el algoritmo de aprendizaje pro refuerze.\n",
    "Las clases principales son las de el **Agente**(Agent) y el **Entorno**(Environment)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import copy\n",
    "\n",
    "Q = {} #dictionary for the Q function [(state, action), value]\n",
    "\n",
    "b = 0.95 #bias parameter (particular to the example)\n",
    "\n",
    "Actions = [0, 1, 2] #list of possible agent's actions (particular to the example)\n",
    "\n",
    "Q[(0,0)] = 0.0 ### some initializations particular to the example\n",
    "amax0 = 0 ### some initializations particular to the example \n",
    "\n",
    "class Envsim: # the necessary methods and data structures for the simulation of the environment\n",
    "\n",
    "      def __init__(self, name):\n",
    "        self.name = name\n",
    "\n",
    "      def rand0(self, state):\n",
    "          s = copy.copy(state)\n",
    "          s = s + 2.0*(random.randint(0, 1) - 0.5)\n",
    "          #print(s, round(s))\n",
    "          return round(s)\n",
    "          \n",
    "      def rand1(self, state):\n",
    "          s = copy.copy(state)\n",
    "          u = random.uniform(0,1)\n",
    "          #print(s)\n",
    "          if u < b:\n",
    "             s = s + 1\n",
    "          else:\n",
    "             s = s - 1\n",
    "          #print(u,s)\n",
    "          return s\n",
    "          \n",
    "      def rand2(self, state):\n",
    "          s = copy.copy(state)\n",
    "          u = random.uniform(0,1)\n",
    "          #print(s)\n",
    "          if u < b:\n",
    "             s = s - 1\n",
    "          else:\n",
    "             s = s + 1\n",
    "          #print(u,s)\n",
    "          return s   \n",
    "\n",
    "      def Enviro(self, state, action): # Given a (state_t, action_t) pair, it generates (s_t+1, r_t+1)\n",
    "          a = copy.copy(action)\n",
    "          s = copy.copy(state)\n",
    "          z = Envsim(self)\n",
    "          r = 0.0\n",
    "          ra = -1.0\n",
    "          rb = 1.0\n",
    "          rc = 0.0\n",
    "          if a==0:\n",
    "             s = z.rand0(state)\n",
    "          if a==1:\n",
    "             s = z.rand1(state)\n",
    "          if a==2:\n",
    "             s = z.rand2(state)\n",
    "          else:\n",
    "             s = s\n",
    "             \n",
    "          if -10 < s < 0:\n",
    "             r = ra\n",
    "          if 0 < s < 10:\n",
    "             r = rb    \n",
    "          if s == 0:\n",
    "             r = rc  \n",
    "          \n",
    "          return s, r\n",
    "                    \n",
    "class Policy: #class for action selection and value updates according to the Q-Learning rule\n",
    "\n",
    "      def __init__(self, name):\n",
    "          self.name = name\n",
    "\n",
    "      def maxq(self, state, Actions):\n",
    "          s = copy.copy(state)\n",
    "          max = -10e10\n",
    "          amax = None\n",
    "          for a in Actions:\n",
    "              u = Q.get(tuple([s,a])) #value associated to the key list [s,a]\n",
    "              if u is None:\n",
    "                 u = -20e10\n",
    "              if u > max:\n",
    "                 amax = copy.copy(a)\n",
    "                 max = copy.copy(u)\n",
    "          #print(s, amax)\n",
    "          return amax\n",
    "          \n",
    "      def epsilon_greedy(self, state, Actions): #epsilon-greedy decisions for systems \n",
    "          #in which is possible to select any action at random given state s\n",
    "          epsilon = 0.1\n",
    "          z = Policy(self)\n",
    "          comple = np.random.rand()\n",
    "          if epsilon > comple:\n",
    "             #chooses and action at random\n",
    "             a = random.randint(0, (len(Actions)-1))\n",
    "             #print(a)\n",
    "             return a\n",
    "          else:\n",
    "              #Returns the action with the maximum Q-value\n",
    "              a = z.maxq(state, Actions)\n",
    "              #print(a)\n",
    "              return a\n",
    "          \n",
    "      def updateq(self, s0,a0,r1,s1,a1):\n",
    "          alpha = 0.2 #learning rate\n",
    "          gamma = 1.0 #discount factor\n",
    "          q0 = Q.get((s0,a0))\n",
    "          if q0 is None:\n",
    "                 q0 = 0.0\n",
    "          q1 = Q.get((s1,a1))\n",
    "          if q1 is None:\n",
    "                 q1 = 0.0\n",
    "          u = q0 + alpha*(r1 + gamma*q1 - q0)         \n",
    "          Q[(s0,a0)] = u\n",
    "          return \n",
    "\n",
    "### These are the generic fundamental classes for Q-learning ###################\n",
    "class Agent:\n",
    "\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        \n",
    "    def action_reset(self):\n",
    "        action = 0\n",
    "        return action\n",
    "          \n",
    "    def act(self, state):\n",
    "        z = Policy(self)\n",
    "        s = copy.copy(state)\n",
    "        #a = z.maxq(s, Actions)\n",
    "        a = z.epsilon_greedy(s, Actions)\n",
    "        #print(a)\n",
    "        return a\n",
    "    \n",
    "    def update(self, state0, action0, reward, state, action):\n",
    "        s0 = copy.copy(state0)\n",
    "        a0 = copy.copy(action0)\n",
    "        r1 = copy.copy(reward)\n",
    "        s1 = copy.copy(state)\n",
    "        a1 = copy.copy(action)\n",
    "        z = Policy(self)\n",
    "        z.updateq(s0,a0,r1,s1,a1)\n",
    "        return\n",
    "\n",
    "class Environment:\n",
    "\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        \n",
    "    def reset(self):\n",
    "          state = 0\n",
    "          return state\n",
    "          \n",
    "    def step(self, state, action):\n",
    "        s = copy.copy(state)\n",
    "        a = copy.copy(action)\n",
    "        z = Envsim(self)\n",
    "        s, r = z.Enviro(s,a)\n",
    "        return s, r\n",
    "    \n",
    "    def done(self, state):\n",
    "        if state == -10 or state == 10:\n",
    "           vdone = True\n",
    "        else:\n",
    "            vdone = False\n",
    "        return vdone"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) Explicar cómo se relacionan las funciones de ambos y cómo se logra en sí la implementación de las funciones en pseudo-código del Algoritmo 1.1 en el programa ql2.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El algoritmo principal de aprendizaje por refuerzo se explica en el pseudocódigo siguiente:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](Alg1.1.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explicación del pseudocódigo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación se explica cada una de las lineas del pseudocódigo y como se relacionan con las lineas del programa del archivo ql2.py. A su vez, las lineas de python correspindientes seran ejecutadas para terminar con el algoritmo completo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Es necesario primero definir al agente y al entorno para el algoritmo, se definen el número máximo de episodios, esto se hace en la variable ```MAX_EPISODE```, en primera instancia este se asigna a un valor de 500. Además también se define la variable del número de pasos que el agente puede recorrer cada iteración ```MAX_TIME```, primero se empieza con 3, para posteriormente cambiarlo a 10 y observar la curva de aprendizaje resultante.\n",
    "Se definen el agente en la variable ```agent``` y el entorno en la vairbale ```env``` con las clases antes definidas. Esto corresponde solo a la línea número uno de el pseudocódigo pues aún no se empieza con los ciclos del entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_EPISODE = 500\n",
    "# Default 3 steps each episode\n",
    "# MAX_TIME = 3 \n",
    "\n",
    "# 2) Permitir al agente explorar 10 pasos cada episodio\n",
    "# MAX_TIME = 10\n",
    "\n",
    "# Dejar que el agente explore 50 pasos para observar la convergencia de la curva de aprendizaje\n",
    "MAX_TIME = 50\n",
    "\n",
    "agent = Agent(\"James Bond\")\n",
    "env = Environment(\"in a dangerous environment\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Se empieza el ciclo que lleva a capo el número de episodios definidos, desde 0 hasta el número máximo de episodios definido ```MAX_EPISODE = 500```. Dentro del ciclo de los episodios se realiza le ejecución del método ```env.reset()```. Para reinicializar el entorno para cada iteración y esto corresponde a la línea 3 del pseudocódigo. Despues se hace ejecuta también el método ```agent.action_reset()``` para el agente para cada iteración. Este paso es necesario ya que el agente y el entorno deben ser reinicializados para asegurar el proceso de aprendizaje."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Se define tambíen una variable ```l``` que va aguardar los valores de la curva de aprendizaje para ser graficada despues de realizar el algoritmo.\n",
    "Comienza el segudo ciclo de 0 al número máximo de pasos ```MAX_TIME = 10```. Dentro de este ciclo se ejecuta el método de estado ```copy.copy(state)```, esto corresponde a la línea 6 del pseudocódigo. Inmediatamente despues se realiza la acción para el agente ```copy.copy(action)``` y se asigna la recompensa con estos previamente asignados ```state, reward = env.step(state0, action0)```. Ahora que se tiene los valores para la recompensa, el estado y la acción, se realiza la actualización del agente con el método ```agent.update(state0, action0, reward, state, action)```, y con esto el agente puede actuar ```action = agent.act(state)```, y este ultimo paso corresponde a la línea 9 del pseudocódigo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = [None] * MAX_EPISODE #list to draw the learning curve\n",
    "\n",
    "for episode in range(MAX_EPISODE):\n",
    "    state = env.reset()\n",
    "    action = agent.action_reset() #depending on the learning problem\n",
    "    cur = 0.0 #cumulative reward for visualization purposes\n",
    "    for t in range(MAX_TIME):\n",
    "        state0 = copy.copy(state)\n",
    "        action0 = copy.copy(action)\n",
    "        state, reward = env.step(state0, action0)                \n",
    "        agent.update(state0, action0, reward, state, action)\n",
    "        action = agent.act(state)\n",
    "        cur = cur + reward\n",
    "        if env.done(state) == True:\n",
    "           break\n",
    "    l[episode] = cur"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Una vez terminado los ciclos esto indica que el proceso de aprendizaje se ha completado, y con los valores de la curva de aprendizaje guardados en la variable ```l```, podemos graficar como se dió esta curva."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) Permitir al agente explorar durante 10 pasos cada episodio. Explicar la curva de aprendizaje resultante."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Puesto que la curva de aprendizaje para 10 pasos por episodio es en el mejor caso caotica para interpretar. Se decidio poner 50 pasos por episodio par observar mejor el comportamiento de la curva de aprendizaje."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(l)\n",
    "plt.savefig(\"./50pasos.png\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al observar la gráfica se puede observar como al paso del tiempo los valores convergen al número de pasos asignados incialmente, esto indica que para cada paso en las iteraciones de los episodios el aprendizajese lleva a cabo, y es al final de las iteraciones donde se consiguen los kejores valores de rendimiento para el algoritmo. Como se puede observar se empieza desde los valores negativos y conforme avanza en los episodios los mínimos disminuyen convergiendo en los número positivos cercanos al número máximo de pasos por episodio. Cuando se le permite al agente explorar 10 pasos por episodio los resultados son más caoticos debido que se necesita más esfuerzo para que el agente aprenda el comportamiento adecuado lo cual oscila entre los errores y es suceptible a los sesgos.\n",
    "\n",
    "Para comparar a continuación se muestra la gráfica resultante para 10 pasos por episodio."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![pasos](pasos.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}